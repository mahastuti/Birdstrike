{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aae4a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# === 1. Pilih fitur & target ===\n",
    "features = [\"jumlah burung pada titik x\", \"titik\", \"hour\", \"dayofweek\", \"is_weekend\", \"waktu_Dini Hari\", \"waktu_Malam\", \"waktu_Pagi\", \"waktu_Siang\", \"waktu_Sore\", \"cuaca_Cerah Berawan\", \"cuaca_Hujan\", \"cuaca_Mendung\", \"fase_Take Off\"]\n",
    "target = \"strike\"\n",
    "\n",
    "# Use the already processed X and y\n",
    "# X = df_model[features]\n",
    "# y = df_model[target]\n",
    "\n",
    "# === 2. Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === 3. Identifikasi kolom kategori ===\n",
    "# Since we used one-hot encoding, there are no categorical features in X_train\n",
    "# If you want to use CatBoost's internal categorical handling, you would need to adjust preprocessing.\n",
    "# For now, we will treat all features as numerical as they are already one-hot encoded or numerical.\n",
    "cat_features = [] # Assuming X is already preprocessed with one-hot encoding\n",
    "\n",
    "# === 4. Hitung scale_pos_weight ===\n",
    "neg, pos = y_train.value_counts()\n",
    "scale_pos_weight = neg / pos\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# === 5. Definisikan CatBoost ===\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    # cat_features=cat_features, # Remove this if treating all as numerical after one-hot\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "# === 6. Training ===\n",
    "# Create CatBoost Pool if using internal categorical handling, otherwise fit directly\n",
    "# train_pool = Pool(data=X_train, label=y_train, cat_features=cat_features)\n",
    "# test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "# cat_model.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n",
    "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100)\n",
    "\n",
    "\n",
    "# === 7. Prediksi & Evaluasi ===\n",
    "y_prob = cat_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = cat_model.predict(X_test)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37c6b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier with treshold tuning\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# ambil probabilitas kelas 1 dari CatBoost\n",
    "y_prob = cat_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# coba beberapa threshold\n",
    "thresholds = [0.5, 0.3, 0.2, 0.1] # dicoba semakin besar (0,9)\n",
    "\n",
    "for thr in thresholds:\n",
    "    print(f\"\\n===== Threshold: {thr} =====\")\n",
    "    y_pred_thr = (y_prob >= thr).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_thr)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10229a1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# EasyEnsembleClassifier (boosting khusus imbalance) & CatBoostClassifier (stabil di data imbalance)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Model base\n",
    "easy = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,  # pakai imbalance ratio\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Meta-model (level-2)\n",
    "meta = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "\n",
    "# Stacking Ensemble\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=[('easy', easy), ('cat', cat)],\n",
    "    final_estimator=meta,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True  # biar meta-model juga dapat input fitur asli\n",
    ")\n",
    "\n",
    "# Training\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi\n",
    "y_pred = stack_model.predict(X_test)\n",
    "y_prob = stack_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Makin jelek jangan dipake\n",
    "# DO NOT USE THIS"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
